{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# importing all the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport string\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential,Model\nfrom tensorflow.keras.layers import Embedding, Input, Bidirectional, LSTM, Dense,RepeatVector,Flatten\n\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.utils import pad_sequences\n\nfrom sklearn.model_selection import train_test_split\nfrom nltk.translate.bleu_score import corpus_bleu\n","metadata":{"execution":{"iopub.status.busy":"2023-06-13T05:47:40.298806Z","iopub.execute_input":"2023-06-13T05:47:40.299203Z","iopub.status.idle":"2023-06-13T05:47:50.798472Z","shell.execute_reply.started":"2023-06-13T05:47:40.299169Z","shell.execute_reply":"2023-06-13T05:47:50.797320Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Text Processing","metadata":{}},{"cell_type":"code","source":"# reading text from file and converting it to lowercase\ntext = open('/kaggle/input/fra-eng-nmt/fra.txt', 'r', encoding='utf-8').read()\ntext = text.lower()","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:53.970690Z","iopub.execute_input":"2023-06-13T06:21:53.971558Z","iopub.status.idle":"2023-06-13T06:21:54.262301Z","shell.execute_reply.started":"2023-06-13T06:21:53.971511Z","shell.execute_reply":"2023-06-13T06:21:54.261148Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# printing some text given in text \nprint(text[:1000])","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:54.264443Z","iopub.execute_input":"2023-06-13T06:21:54.264824Z","iopub.status.idle":"2023-06-13T06:21:54.270763Z","shell.execute_reply.started":"2023-06-13T06:21:54.264783Z","shell.execute_reply":"2023-06-13T06:21:54.269570Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"go.\tva !\tcc-by 2.0 (france) attribution: tatoeba.org #2877272 (cm) & #1158250 (wittydev)\ngo.\tmarche.\tcc-by 2.0 (france) attribution: tatoeba.org #2877272 (cm) & #8090732 (micsmithel)\ngo.\ten route !\tcc-by 2.0 (france) attribution: tatoeba.org #2877272 (cm) & #8267435 (felix63)\ngo.\tbouge !\tcc-by 2.0 (france) attribution: tatoeba.org #2877272 (cm) & #9022935 (micsmithel)\nhi.\tsalut !\tcc-by 2.0 (france) attribution: tatoeba.org #538123 (cm) & #509819 (aiji)\nhi.\tsalut.\tcc-by 2.0 (france) attribution: tatoeba.org #538123 (cm) & #4320462 (gillux)\nrun!\tcours !\tcc-by 2.0 (france) attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)\nrun!\tcourez !\tcc-by 2.0 (france) attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)\nrun!\tprenez vos jambes à vos cous !\tcc-by 2.0 (france) attribution: tatoeba.org #906328 (papabear) & #2077449 (sacredceltic)\nrun!\tfile !\tcc-by 2.0 (france) attribution: tatoeba.org #906328 (papabear) & #2077454 (sacredceltic)\nrun!\tfilez !\tcc-by 2.0 (fr\n","output_type":"stream"}]},{"cell_type":"code","source":"# splitiing text line by line and printing 1st line\nsentences = text.split('\\n')\nprint(sentences[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:54.447689Z","iopub.execute_input":"2023-06-13T06:21:54.448027Z","iopub.status.idle":"2023-06-13T06:21:54.529630Z","shell.execute_reply.started":"2023-06-13T06:21:54.447998Z","shell.execute_reply":"2023-06-13T06:21:54.528283Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"go.\tva !\tcc-by 2.0 (france) attribution: tatoeba.org #2877272 (cm) & #1158250 (wittydev)\n","output_type":"stream"}]},{"cell_type":"code","source":"# splitiing text\nsentences = [i.split('\\t')[:-1] for i in sentences]\nprint(sentences[0])","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:54.671158Z","iopub.execute_input":"2023-06-13T06:21:54.672057Z","iopub.status.idle":"2023-06-13T06:21:55.243037Z","shell.execute_reply.started":"2023-06-13T06:21:54.672008Z","shell.execute_reply":"2023-06-13T06:21:55.241826Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"['go.', 'va !']\n","output_type":"stream"}]},{"cell_type":"code","source":"# punctuations used for removing from text\npunctuations = string.punctuation\nprint(punctuations)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:55.245366Z","iopub.execute_input":"2023-06-13T06:21:55.246179Z","iopub.status.idle":"2023-06-13T06:21:55.257392Z","shell.execute_reply.started":"2023-06-13T06:21:55.246127Z","shell.execute_reply":"2023-06-13T06:21:55.255910Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","output_type":"stream"}]},{"cell_type":"code","source":"# removing punctuations\nfor i,l in enumerate(sentences):\n    for j,s in enumerate(l):\n        for p in punctuations:\n            s = s.replace(p,'')\n        sentences[i][j] = s\n    ","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:55.259178Z","iopub.execute_input":"2023-06-13T06:21:55.260445Z","iopub.status.idle":"2023-06-13T06:21:58.954035Z","shell.execute_reply.started":"2023-06-13T06:21:55.260405Z","shell.execute_reply":"2023-06-13T06:21:58.952929Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"# sentences looks like after removing punctuations\nsentences[350:355]","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:58.956793Z","iopub.execute_input":"2023-06-13T06:21:58.957274Z","iopub.status.idle":"2023-06-13T06:21:58.966493Z","shell.execute_reply.started":"2023-06-13T06:21:58.957234Z","shell.execute_reply":"2023-06-13T06:21:58.965407Z"},"trusted":true},"execution_count":39,"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"[['im hit', 'je suis touchée '],\n ['im ill', 'je suis malade'],\n ['im sad', 'je suis triste'],\n ['im sad', 'jai un coup de cafard'],\n ['im sad', 'je suis malheureux']]"},"metadata":{}}]},{"cell_type":"code","source":"# adding keys to decoder text so that model recognizes where to stop predicting\nfor i in range(len(sentences)):\n    if len(sentences[i]) != 0:\n        sentences[i][1] = '<start> '+sentences[i][1]+' <end>'\nsentences[0:5]","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:58.968035Z","iopub.execute_input":"2023-06-13T06:21:58.969088Z","iopub.status.idle":"2023-06-13T06:21:59.127149Z","shell.execute_reply.started":"2023-06-13T06:21:58.969048Z","shell.execute_reply":"2023-06-13T06:21:59.125964Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"[['go', '<start> va  <end>'],\n ['go', '<start> marche <end>'],\n ['go', '<start> en route  <end>'],\n ['go', '<start> bouge  <end>'],\n ['hi', '<start> salut  <end>']]"},"metadata":{}}]},{"cell_type":"markdown","source":"## splitting the data","metadata":{"execution":{"iopub.status.busy":"2023-06-10T13:00:36.209810Z","iopub.execute_input":"2023-06-10T13:00:36.210636Z","iopub.status.idle":"2023-06-10T13:00:36.568515Z","shell.execute_reply.started":"2023-06-10T13:00:36.210557Z","shell.execute_reply":"2023-06-10T13:00:36.567321Z"}}},{"cell_type":"code","source":"# We use only 10% of data for training due to less resources.\ntrain,test = train_test_split(sentences,test_size=0.90,random_state=123)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:59.129021Z","iopub.execute_input":"2023-06-13T06:21:59.129442Z","iopub.status.idle":"2023-06-13T06:21:59.247533Z","shell.execute_reply.started":"2023-06-13T06:21:59.129399Z","shell.execute_reply":"2023-06-13T06:21:59.245036Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"len(train),len(test)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:59.251340Z","iopub.execute_input":"2023-06-13T06:21:59.252187Z","iopub.status.idle":"2023-06-13T06:21:59.272434Z","shell.execute_reply.started":"2023-06-13T06:21:59.252130Z","shell.execute_reply":"2023-06-13T06:21:59.266336Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"(20890, 188017)"},"metadata":{}}]},{"cell_type":"code","source":"# splitting eng and fra train data\ntrain_eng,train_fra = [],[]\nfor i in train:\n    if len(i) != 0:\n        train_eng.append(i[0])\n        train_fra.append(i[1])\n\ntrain_eng[0],train_fra[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:59.275269Z","iopub.execute_input":"2023-06-13T06:21:59.275962Z","iopub.status.idle":"2023-06-13T06:21:59.343999Z","shell.execute_reply.started":"2023-06-13T06:21:59.275928Z","shell.execute_reply":"2023-06-13T06:21:59.335524Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"('i checked the list', '<start> jai vérifié la liste <end>')"},"metadata":{}}]},{"cell_type":"code","source":"# splitting eng and fra test data\ntest_eng,test_fra = [],[]\nfor j in test:\n    if len(j) != 0:\n        test_eng.append(j[0])\n        test_fra.append(j[1])\n        \ntest_eng[0],test_fra[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:59.345970Z","iopub.execute_input":"2023-06-13T06:21:59.348018Z","iopub.status.idle":"2023-06-13T06:21:59.576434Z","shell.execute_reply.started":"2023-06-13T06:21:59.347969Z","shell.execute_reply":"2023-06-13T06:21:59.575325Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"('you had better make sure that he is at home before you call on him',\n '<start> vous devriez vous assurer quil est chez lui avant de lui rendre visite <end>')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preparation for Training","metadata":{}},{"cell_type":"code","source":"# creating tokenizer for converting text to numbers\ntokenizer_eng = Tokenizer(oov_token='<UNKE>',filters = '')\ntokenizer_fra = Tokenizer(oov_token='<UNKF>',filters = '')","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:59.577962Z","iopub.execute_input":"2023-06-13T06:21:59.578837Z","iopub.status.idle":"2023-06-13T06:21:59.586909Z","shell.execute_reply.started":"2023-06-13T06:21:59.578797Z","shell.execute_reply":"2023-06-13T06:21:59.585823Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# fitting tokenizer according to words in train data set\ntokenizer_eng.fit_on_texts(train_eng)\ntokenizer_fra.fit_on_texts(train_fra)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:21:59.589939Z","iopub.execute_input":"2023-06-13T06:21:59.590455Z","iopub.status.idle":"2023-06-13T06:22:00.141838Z","shell.execute_reply.started":"2023-06-13T06:21:59.590391Z","shell.execute_reply":"2023-06-13T06:22:00.140691Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# total vocab size of both languages(train)\nvocab_size_eng = len(tokenizer_eng.word_index) + 1\nvocab_size_fra = len(tokenizer_fra.word_index) + 1\nvocab_size_eng,vocab_size_fra","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:22:00.143637Z","iopub.execute_input":"2023-06-13T06:22:00.144364Z","iopub.status.idle":"2023-06-13T06:22:00.153218Z","shell.execute_reply.started":"2023-06-13T06:22:00.144320Z","shell.execute_reply":"2023-06-13T06:22:00.152024Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"(6900, 12497)"},"metadata":{}}]},{"cell_type":"code","source":"# converting text to sequences according to tokenizer\nsequences_eng = tokenizer_eng.texts_to_sequences(train_eng)\nsequences_fra = tokenizer_fra.texts_to_sequences(train_fra)\n\n# output for training a model lag by one timestep\nsequences_fra_out = [i[1:] for i in sequences_fra]","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:22:00.439334Z","iopub.execute_input":"2023-06-13T06:22:00.440079Z","iopub.status.idle":"2023-06-13T06:22:00.846840Z","shell.execute_reply.started":"2023-06-13T06:22:00.440036Z","shell.execute_reply":"2023-06-13T06:22:00.845518Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"sequences_eng[0],sequences_fra[0],sequences_fra_out[0]","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:22:01.334459Z","iopub.execute_input":"2023-06-13T06:22:01.336631Z","iopub.status.idle":"2023-06-13T06:22:01.346233Z","shell.execute_reply.started":"2023-06-13T06:22:01.336569Z","shell.execute_reply":"2023-06-13T06:22:01.344982Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"([2, 1343, 5, 784], [2, 24, 2006, 10, 890, 3], [24, 2006, 10, 890, 3])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting max seq length of both languages(train)\nmax_seq_len_eng = max([len(seq) for seq in sequences_eng])\nmax_seq_len_fra = max([len(seq) for seq in sequences_fra])\nmax_seq_len_eng,max_seq_len_fra","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:30:40.993991Z","iopub.execute_input":"2023-06-13T06:30:40.995123Z","iopub.status.idle":"2023-06-13T06:30:41.012685Z","shell.execute_reply.started":"2023-06-13T06:30:40.995073Z","shell.execute_reply":"2023-06-13T06:30:41.011479Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"(34, 49)"},"metadata":{}}]},{"cell_type":"code","source":"# padding to get the data of same length\npadded_sequences_eng = pad_sequences(sequences_eng, maxlen = max_seq_len_eng,padding = 'post')\npadded_sequences_fra = pad_sequences(sequences_fra, maxlen = max_seq_len_fra,padding = 'post')\npadded_sequences_fra_out = pad_sequences(sequences_fra_out, maxlen = max_seq_len_fra,padding = 'post')","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:32:05.160162Z","iopub.execute_input":"2023-06-13T06:32:05.161181Z","iopub.status.idle":"2023-06-13T06:32:05.457590Z","shell.execute_reply.started":"2023-06-13T06:32:05.161139Z","shell.execute_reply":"2023-06-13T06:32:05.456488Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Final Shape of data\nprint(padded_sequences_eng.shape)\nprint(padded_sequences_fra.shape)\nprint(padded_sequences_fra_out.shape)","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:32:07.715687Z","iopub.execute_input":"2023-06-13T06:32:07.716448Z","iopub.status.idle":"2023-06-13T06:32:07.723921Z","shell.execute_reply.started":"2023-06-13T06:32:07.716407Z","shell.execute_reply":"2023-06-13T06:32:07.722847Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"(20890, 34)\n(20890, 49)\n(20890, 49)\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating generator to load data to model batch by batch t\ndef train_generator(eng,fra,fra_oh,batch=128):\n    l = len(eng)\n    count=0\n    while count <= l:\n        eng_data = eng[count:count+batch]\n        fra_data = fra[count:count+batch]\n        fra_out_data = fra_oh[count:count+batch]\n        # converting output data into one hot encoding\n        fra_out_data = keras.utils.to_categorical(fra_out_data,num_classes = vocab_size_fra)\n        count += batch\n        yield [eng_data,fra_data],fra_out_data","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:34:58.247875Z","iopub.execute_input":"2023-06-13T06:34:58.248537Z","iopub.status.idle":"2023-06-13T06:34:58.256170Z","shell.execute_reply.started":"2023-06-13T06:34:58.248498Z","shell.execute_reply":"2023-06-13T06:34:58.255032Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"## Model Creation and Training","metadata":{}},{"cell_type":"code","source":"# Model Pipiline\n\nlen_embed = 256\n## encoder\n# english imput data\nenc_inp = Input(shape=(None,))   \n# creating an embedding layer to convert data into different dimensions\nenc_emb = Embedding(vocab_size_eng,len_embed,mask_zero = True)(enc_inp)  \n# pass embedded text to lstm which return states\nenc_lstm = LSTM(len_embed,return_state = True)\n\n# out states of lstm\nenc_out,enc_st_h,enc_st_c = enc_lstm(enc_emb)\nenc_state = [enc_st_h,enc_st_c] ","metadata":{"execution":{"iopub.status.busy":"2023-06-13T06:37:11.751380Z","iopub.execute_input":"2023-06-13T06:37:11.752187Z","iopub.status.idle":"2023-06-13T06:37:16.729325Z","shell.execute_reply.started":"2023-06-13T06:37:11.752145Z","shell.execute_reply":"2023-06-13T06:37:16.728200Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"## decoder\n# framce imput data\ndec_inp = Input(shape=(None,))\n# creating an embedding layer to convert data into different dimensions\ndec_emb_layer = Embedding(vocab_size_fra,len_embed,mask_zero=True)\ndec_emb = dec_emb_layer(dec_inp)\n# pass embedded text to lstm which return output\ndec_lstm = LSTM(len_embed,return_sequences=True,return_state=True)\ndec_out,_,_ = dec_lstm(dec_emb,initial_state = enc_state)\n# passing out of decoder through dense layer\ndec_dense = Dense(vocab_size_fra,activation='softmax')\ndec_dense_out = dec_dense(dec_out)\n\n# Model Completed\nmodel = Model([enc_inp,dec_inp],dec_dense_out)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-10T13:00:44.796320Z","iopub.execute_input":"2023-06-10T13:00:44.796945Z","iopub.status.idle":"2023-06-10T13:00:45.798691Z","shell.execute_reply.started":"2023-06-10T13:00:44.796886Z","shell.execute_reply":"2023-06-10T13:00:45.797845Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_1 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n input_2 (InputLayer)           [(None, None)]       0           []                               \n                                                                                                  \n embedding (Embedding)          (None, None, 256)    1766400     ['input_1[0][0]']                \n                                                                                                  \n embedding_1 (Embedding)        (None, None, 256)    3199232     ['input_2[0][0]']                \n                                                                                                  \n lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n                                 (None, 256),                                                     \n                                 (None, 256)]                                                     \n                                                                                                  \n lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n                                 (None, 256),                     'lstm[0][1]',                   \n                                 (None, 256)]                     'lstm[0][2]']                   \n                                                                                                  \n dense (Dense)                  (None, None, 12497)  3211729     ['lstm_1[0][0]']                 \n                                                                                                  \n==================================================================================================\nTotal params: 9,227,985\nTrainable params: 9,227,985\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compiling Model\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])","metadata":{"execution":{"iopub.status.busy":"2023-06-10T13:00:45.799808Z","iopub.execute_input":"2023-06-10T13:00:45.800200Z","iopub.status.idle":"2023-06-10T13:00:45.831006Z","shell.execute_reply.started":"2023-06-10T13:00:45.800158Z","shell.execute_reply":"2023-06-10T13:00:45.829837Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Training Model for 50 epochs\nbatch=128\nfor i in range(50):\n    model.fit(train_generator(padded_sequences_eng,padded_sequences_fra,padded_sequences_fra_oh,batch),steps_per_epoch=len(padded_sequences_eng)//batch)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T13:00:45.832871Z","iopub.execute_input":"2023-06-10T13:00:45.833294Z","iopub.status.idle":"2023-06-10T14:36:45.216540Z","shell.execute_reply.started":"2023-06-10T13:00:45.833252Z","shell.execute_reply":"2023-06-10T14:36:45.215311Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"163/163 [==============================] - 112s 594ms/step - loss: 5.9688 - acc: 0.2016\n163/163 [==============================] - 88s 540ms/step - loss: 4.8612 - acc: 0.2941\n163/163 [==============================] - 88s 541ms/step - loss: 4.5110 - acc: 0.3187\n163/163 [==============================] - 88s 540ms/step - loss: 4.1957 - acc: 0.3454\n163/163 [==============================] - 88s 539ms/step - loss: 3.9138 - acc: 0.3715\n163/163 [==============================] - 87s 536ms/step - loss: 3.6704 - acc: 0.3973\n163/163 [==============================] - 87s 533ms/step - loss: 3.4548 - acc: 0.4212\n163/163 [==============================] - 87s 532ms/step - loss: 3.2663 - acc: 0.4392\n163/163 [==============================] - 86s 530ms/step - loss: 3.0979 - acc: 0.4559\n163/163 [==============================] - 87s 531ms/step - loss: 2.9449 - acc: 0.4707\n163/163 [==============================] - 87s 533ms/step - loss: 2.8046 - acc: 0.4842\n163/163 [==============================] - 87s 534ms/step - loss: 2.6699 - acc: 0.4981\n163/163 [==============================] - 87s 533ms/step - loss: 2.5383 - acc: 0.5119\n163/163 [==============================] - 87s 535ms/step - loss: 2.4146 - acc: 0.5254\n163/163 [==============================] - 87s 533ms/step - loss: 2.2960 - acc: 0.5384\n163/163 [==============================] - 87s 534ms/step - loss: 2.1810 - acc: 0.5525\n163/163 [==============================] - 87s 533ms/step - loss: 2.0724 - acc: 0.5662\n163/163 [==============================] - 87s 531ms/step - loss: 1.9671 - acc: 0.5825\n163/163 [==============================] - 87s 533ms/step - loss: 1.8661 - acc: 0.5989\n163/163 [==============================] - 87s 534ms/step - loss: 1.7702 - acc: 0.6161\n163/163 [==============================] - 87s 532ms/step - loss: 1.6719 - acc: 0.6341\n163/163 [==============================] - 86s 529ms/step - loss: 1.5742 - acc: 0.6551\n163/163 [==============================] - 87s 534ms/step - loss: 1.4834 - acc: 0.6734\n163/163 [==============================] - 87s 536ms/step - loss: 1.4001 - acc: 0.6913\n163/163 [==============================] - 86s 530ms/step - loss: 1.3213 - acc: 0.7085\n163/163 [==============================] - 86s 527ms/step - loss: 1.2500 - acc: 0.7246\n163/163 [==============================] - 87s 533ms/step - loss: 1.1812 - acc: 0.7401\n163/163 [==============================] - 87s 531ms/step - loss: 1.1151 - acc: 0.7553\n163/163 [==============================] - 88s 538ms/step - loss: 1.0551 - acc: 0.7682\n163/163 [==============================] - 87s 533ms/step - loss: 0.9984 - acc: 0.7816\n163/163 [==============================] - 86s 529ms/step - loss: 0.9404 - acc: 0.7950\n163/163 [==============================] - 87s 530ms/step - loss: 0.8811 - acc: 0.8099\n163/163 [==============================] - 87s 535ms/step - loss: 0.8271 - acc: 0.8224\n163/163 [==============================] - 87s 533ms/step - loss: 0.7769 - acc: 0.8356\n163/163 [==============================] - 87s 532ms/step - loss: 0.7313 - acc: 0.8463\n163/163 [==============================] - 86s 529ms/step - loss: 0.6879 - acc: 0.8561\n163/163 [==============================] - 87s 531ms/step - loss: 0.6453 - acc: 0.8663\n163/163 [==============================] - 87s 532ms/step - loss: 0.6040 - acc: 0.8757\n163/163 [==============================] - 86s 528ms/step - loss: 0.5667 - acc: 0.8854\n163/163 [==============================] - 87s 532ms/step - loss: 0.5319 - acc: 0.8931\n163/163 [==============================] - 87s 532ms/step - loss: 0.4998 - acc: 0.9007\n163/163 [==============================] - 87s 531ms/step - loss: 0.4698 - acc: 0.9081\n163/163 [==============================] - 86s 530ms/step - loss: 0.4401 - acc: 0.9147\n163/163 [==============================] - 87s 533ms/step - loss: 0.4138 - acc: 0.9216\n163/163 [==============================] - 87s 533ms/step - loss: 0.3895 - acc: 0.9261\n163/163 [==============================] - 87s 532ms/step - loss: 0.3660 - acc: 0.9316\n163/163 [==============================] - 87s 532ms/step - loss: 0.3432 - acc: 0.9368\n163/163 [==============================] - 87s 533ms/step - loss: 0.3206 - acc: 0.9418\n163/163 [==============================] - 87s 535ms/step - loss: 0.2982 - acc: 0.9468\n163/163 [==============================] - 87s 532ms/step - loss: 0.2768 - acc: 0.9513\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing","metadata":{}},{"cell_type":"code","source":"# model for prediction\n# for english data prediction\nenc_model = Model(enc_inp,enc_state)\n\n# taking an empty input tensor for decoder states\ndec_st_h = Input(shape=(len_embed,))\ndec_st_c = Input(shape=(len_embed,))\ndec_st = [dec_st_h,dec_st_c]\n\ndec_tst_emb = dec_emb_layer(dec_inp)\n\n# passing decoder text to decoder lstm layer and saving out and states for passing it to next time for prediction\ndec_tst_out,dec_tst_h,dec_tst_c = dec_lstm(dec_tst_emb,initial_state = dec_st)\ndec_tst_st = [dec_tst_h,dec_tst_c]\ndec_tst_den_out = dec_dense(dec_tst_out)\n\n# decoder Model Completed\ndec_model = Model([dec_inp]+dec_st, [dec_tst_den_out]+dec_tst_st)","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:36:56.511852Z","iopub.execute_input":"2023-06-10T14:36:56.512620Z","iopub.status.idle":"2023-06-10T14:36:57.405005Z","shell.execute_reply.started":"2023-06-10T14:36:56.512569Z","shell.execute_reply":"2023-06-10T14:36:57.403866Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# for saving model\nmodel.save('enc_dec.h5')\ndec_model.save('dec_test.h5')","metadata":{"execution":{"iopub.status.busy":"2023-06-10T15:23:38.571924Z","iopub.execute_input":"2023-06-10T15:23:38.572916Z","iopub.status.idle":"2023-06-10T15:23:38.902289Z","shell.execute_reply.started":"2023-06-10T15:23:38.572849Z","shell.execute_reply":"2023-06-10T15:23:38.900776Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# prediction and bleu score calculation\nfor i in range(10):\n    print(i+1)\n    predicted = '<start>'\n    inp1 = [test_eng[i]]\n    inp1 = tokenizer_eng.texts_to_sequences(inp1)\n    inp1 = pad_sequences(inp1, maxlen = max_seq_len_eng,padding = 'post')\n    inp_st = enc_model.predict(inp1,verbose=0)\n    inp2 = ['<start>']\n    inp2 = np.array(tokenizer_fra.texts_to_sequences(inp2))\n\n    while True:\n        out,h,c = dec_model.predict([inp2]+inp_st,verbose=0)\n        inp_st = [h,c]\n        out = np.argmax(out[0][-1]) \n        inp2[0][0] = out\n        \n        for k,v in tokenizer_fra.word_index.items():\n            if out == v:\n                out = k\n                break\n        predicted += ' ' + out\n\n        if out == '<end>' or len(predicted.split()) > 47:\n            break\n\n    \n    print('Eng :- ',test_eng[i])\n    print('Fra actual :- ',test_fra[i])\n    print('Fra predicted :- ',predicted)\n    print('Bleu Score :- ',corpus_bleu([test_fra[i][8:-6]],[predicted[:-6]]))\n                   ","metadata":{"execution":{"iopub.status.busy":"2023-06-10T14:41:05.356094Z","iopub.execute_input":"2023-06-10T14:41:05.357216Z","iopub.status.idle":"2023-06-10T14:41:10.906940Z","shell.execute_reply.started":"2023-06-10T14:41:05.357161Z","shell.execute_reply":"2023-06-10T14:41:10.905764Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"1\nEng :-  you had better make sure that he is at home before you call on him\nFra actual :-  <start> vous devriez vous assurer quil est chez lui avant de lui rendre visite <end>\nFra predicted :-  <start> tu ferais mieux de vous dire combien de la police était juste à la maison <end>\nBleu Score :-  0.6447788067558897\n2\nEng :-  im not accustomed to eating this kind of food\nFra actual :-  <start> je ne suis pas habitué à manger ce genre de nourriture <end>\nFra predicted :-  <start> je ne suis pas qualifié mais je ne le serai pas en retard <end>\nBleu Score :-  0.6812455364200614\n3\nEng :-  youre generous\nFra actual :-  <start> tu es généreux <end>\nFra predicted :-  <start> tu es fort <end>\nBleu Score :-  0.7598356856515925\n4\nEng :-  i remember reading about it\nFra actual :-  <start> je me rappelle avoir lu à ce propos <end>\nFra predicted :-  <start> je me souviens avoir lu à ce sujet <end>\nBleu Score :-  0.7598356856515925\n5\nEng :-  its about time\nFra actual :-  <start> il est temps  <end>\nFra predicted :-  <start> cest pour ça <end>\nBleu Score :-  0.7071067811865476\n6\nEng :-  keep back\nFra actual :-  <start> restez en arrière <end>\nFra predicted :-  <start> continue à rouler <end>\nBleu Score :-  0.7521206186172787\n7\nEng :-  do you really think tom can win\nFra actual :-  <start> tu penses vraiment que tom peut gagner  <end>\nFra predicted :-  <start> veuxtu vraiment croire tom <end>\nBleu Score :-  0.7707713836060629\n8\nEng :-  english is the language of the world\nFra actual :-  <start> langlais est la langue du monde <end>\nFra predicted :-  <start> lentraînement est complètement déserté <end>\nBleu Score :-  0.6828267746069693\n9\nEng :-  my husband was called away on business\nFra actual :-  <start> mon mari a été appelé en voyage daffaires <end>\nFra predicted :-  <start> mon nom est toujours à létranger <end>\nBleu Score :-  0.7400828044922853\n10\nEng :-  the village in which he was born is far from here\nFra actual :-  <start> le village dans lequel il est né est loin dici <end>\nFra predicted :-  <start> dans le monde est occupée et le silence était en retard <end>\nBleu Score :-  0.6739857287654524\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}